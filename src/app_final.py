import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import re
import joblib
import cv2
import math
import time
import requests
import mediapipe as mp
from datetime import datetime, timedelta
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# -----------------------------------------------------------------------------
# 1. ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ
# -----------------------------------------------------------------------------
st.set_page_config(page_title="Smart PC Builder", layout="wide")
plt.rc('font', family='Malgun Gothic')
plt.rcParams['axes.unicode_minus'] = False

# [ìŠ¤íƒ€ì¼] í°íŠ¸: ì–‡ê³  í˜„ëŒ€ì ì¸ SIMPLEX (ìœ ì§€)
MY_FONT = cv2.FONT_HERSHEY_SIMPLEX 

# [ì‚¬ìš©ì ê²½ë¡œ ê³ ì •]
PROJECT_ROOT = r'D:\minwoo\project\Virtual-Build-PC'
BASE_DATA_DIR = os.path.join(PROJECT_ROOT, 'Dataset')
MODEL_DIR = os.path.join(PROJECT_ROOT, 'models')
MOUSE_DATA_PATH = os.path.join(BASE_DATA_DIR, 'mouse_specs.csv')

try:
    import tensorflow as tf
    from tensorflow.keras.models import load_model
    HAS_TF = True
except ImportError:
    HAS_TF = False
    print("âš ï¸ TensorFlow ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# -----------------------------------------------------------------------------
# 2. ê³µí†µ í•¨ìˆ˜ (ë¡œì§ 100% ìœ ì§€)
# -----------------------------------------------------------------------------
@st.cache_data
def get_model_list(category):
    folder_map = {"VGA": "VGA_Total", "CPU": "CPU_Total", "RAM": "RAM_Total"}
    target_folder = os.path.join(BASE_DATA_DIR, folder_map.get(category, ""))
    if not os.path.exists(target_folder): return [], target_folder
    files = sorted([f for f in os.listdir(target_folder) if f.endswith('.csv')])
    if not files: return [], target_folder
    try:
        latest = files[-1]
        path = os.path.join(target_folder, latest)
        try: df = pd.read_csv(path, encoding='utf-8')
        except: df = pd.read_csv(path, encoding='cp949')
        def cleaner(name):
            if not isinstance(name, str): return None
            if category == "VGA": match = re.search(r'(RTX|RX|GTX)\s?\d{3,4}\s?(Ti|SUPER|XT|XTX|GRE)?', name, re.I)
            elif category == "CPU": match = re.search(r'(i\d-\d{4,5}[KF]*|Ryzen\s?\d\s?\d{4}[GX]?)', name, re.I)
            elif category == "RAM": match = re.search(r'(DDR\d-\d{4})', name, re.I)
            else: return None
            return match.group(0).strip() if match else None
        if 'Name' in df.columns: return sorted(df['Name'].apply(cleaner).dropna().unique().tolist()), target_folder
        return [], target_folder
    except: return [], target_folder

@st.cache_data
def load_data(folder_path, target_model, category):
    all_data = []
    files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]
    for f in files:
        path = os.path.join(folder_path, f)
        df_tmp = None
        for enc in ['utf-8', 'cp949']:
            try: df_tmp = pd.read_csv(path, encoding=enc); break
            except: continue
        if df_tmp is None or 'Name' not in df_tmp.columns: continue
        rows = df_tmp[df_tmp['Name'].str.contains(target_model, na=False, case=False)]
        cols = [c for c in df_tmp.columns if re.match(r'\d{4}-\d{2}-\d{2}', c)]
        for col in cols:
            p = pd.to_numeric(rows[col].astype(str).str.replace(',', '').str.extract('(\d+)')[0], errors='coerce')
            limit = 3000 if category == "RAM" else 10000
            valid = p[p > limit]
            if not valid.empty: all_data.append({'Date': col.split(' ')[0], 'Price': valid.mean()})
    if not all_data: return None
    df = pd.DataFrame(all_data).groupby('Date')['Price'].mean().reset_index()
    df['Date_dt'] = pd.to_datetime(df['Date'])
    df = df.sort_values('Date_dt')
    df['Year'] = df['Date_dt'].dt.year
    df['Month'] = df['Date_dt'].dt.month
    df['DayOfWeek'] = df['Date_dt'].dt.dayofweek
    df['Price_Raw'] = df['Price']
    df['Price_Smooth'] = df['Price'].rolling(window=3, min_periods=1).mean()
    return df

@st.cache_data
def load_mouse_data():
    if not os.path.exists(MOUSE_DATA_PATH): return pd.DataFrame()
    try: df = pd.read_csv(MOUSE_DATA_PATH, encoding='utf-8-sig')
    except:
        try: df = pd.read_csv(MOUSE_DATA_PATH, encoding='cp949')
        except: return pd.DataFrame()
    rename_map = {'Manufacturer': 'Brand', 'Grip_Type': 'Grip', 'Image_URL': 'image_url'}
    df.rename(columns=rename_map, inplace=True)
    df.columns = df.columns.str.strip() 
    if 'Brand' in df.columns: df['Brand'] = df['Brand'].astype(str).str.title() 
    if 'Length' in df.columns:
        if 'Price' in df.columns:
            df['Price'] = pd.to_numeric(df['Price'].astype(str).str.replace(',', ''), errors='coerce').fillna(0).astype(int)
        for col in ['Length', 'Width', 'Height']:
            if col in df.columns: df[col] = pd.to_numeric(df[col], errors='coerce')
        df = df[df['Length'] > 0].copy()
    return df

@st.cache_data(show_spinner=False)
def get_mouse_image_from_url(url):
    """[ìœ ì§€] í°ìƒ‰ ë§ˆìš°ìŠ¤ ê¹¨ì§ ë°©ì§€ (Contour ë°©ì‹)"""
    try:
        if not str(url).startswith('http'): return None
        resp = requests.get(url, timeout=3)
        if resp.status_code == 200:
            image_array = np.asarray(bytearray(resp.content), dtype=np.uint8)
            img = cv2.imdecode(image_array, cv2.IMREAD_UNCHANGED)
            if img is None: return None
            if img.shape[2] == 3: img = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)
            gray = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)
            _, binary = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)
            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if contours:
                max_cnt = max(contours, key=cv2.contourArea)
                mask = np.zeros_like(gray)
                cv2.drawContours(mask, [max_cnt], -1, 255, thickness=cv2.FILLED)
                img[:, :, 3] = mask
                x, y, w, h = cv2.boundingRect(max_cnt)
                pad = 10
                img = img[max(0, y-pad):min(img.shape[0], y+h+pad), max(0, x-pad):min(img.shape[1], x+w+pad)]
                return img
    except: return None
    return None

def rotate_image_with_matrix(image, angle):
    h, w = image.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    cos, sin = np.abs(M[0, 0]), np.abs(M[0, 1])
    new_w, new_h = int((h * sin) + (w * cos)), int((h * cos) + (w * sin))
    M[0, 2] += (new_w / 2) - center[0]; M[1, 2] += (new_h / 2) - center[1]
    return cv2.warpAffine(image, M, (new_w, new_h), borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0,0)), M

def rotate_image(image, angle):
    img, _ = rotate_image_with_matrix(image, angle)
    return img

def overlay_transparent(background, overlay, x, y, overlay_size=None, global_alpha=1.0):
    bg_h, bg_w, _ = background.shape
    if overlay_size is not None: overlay = cv2.resize(overlay, overlay_size)
    h, w, _ = overlay.shape
    if x >= bg_w or y >= bg_h or x + w < 0 or y + h < 0: return background
    bg_x, bg_y = max(x, 0), max(y, 0)
    ol_x, ol_y = max(0, -x), max(0, -y)
    w, h = min(w - ol_x, bg_w - bg_x), min(h - ol_y, bg_h - bg_y)
    if w <= 0 or h <= 0: return background
    overlay_crop = overlay[ol_y:ol_y+h, ol_x:ol_x+w]
    bg_crop = background[bg_y:bg_y+h, bg_x:bg_x+w]
    alpha = (overlay_crop[:, :, 3] / 255.0) * global_alpha
    inv_alpha = 1.0 - alpha
    for i in range(3):
        bg_crop[:, :, i] = (alpha * overlay_crop[:, :, i] + inv_alpha * bg_crop[:, :, i])
    background[bg_y:bg_y+h, bg_x:bg_x+w] = bg_crop
    return background

def nothing(x): pass

# -----------------------------------------------------------------------------
# 3. ë©”ì¸ ë¡œì§
# -----------------------------------------------------------------------------
st.sidebar.title("ğŸ’ Smart PC Builder")
page_mode = st.sidebar.selectbox("ê¸°ëŠ¥ì„ ì„ íƒí•˜ì„¸ìš”", ["ğŸ–¥ï¸ ë¶€í’ˆ ì‹œì„¸ ë¶„ì„", "ğŸ–±ï¸ ë§ˆìš°ìŠ¤ ê°€ìƒ í”¼íŒ…ë£¸"])

# =============================================================================
# [MODE 1] ë¶€í’ˆ ì‹œì„¸ ë¶„ì„ (ë¡œì§ 100% ìœ ì§€)
# =============================================================================
if page_mode == "ğŸ–¥ï¸ ë¶€í’ˆ ì‹œì„¸ ë¶„ì„":
    if not HAS_TF: st.error("âŒ TensorFlow ë¯¸ì„¤ì¹˜")
    else:
        st.sidebar.header("ğŸ› ï¸ ë¶€í’ˆ ì„¤ì •")
        category = st.sidebar.radio("ë¶€í’ˆ ì¢…ë¥˜", ["VGA", "CPU", "RAM"])
        model_list, folder_path = get_model_list(category)

        if model_list:
            idx = 0
            defaults = {"VGA": "RTX 4060", "CPU": "i5-13400", "RAM": "DDR5-5600"}
            for i, name in enumerate(model_list):
                if defaults.get(category, "") in name: idx = i; break
            selected_model = st.sidebar.selectbox("ëª¨ë¸ëª… ì„ íƒ", model_list, index=idx)
        else: st.error(f"âŒ '{category}' ë°ì´í„° ì—†ìŒ"); st.stop()

        st.title(f"ğŸ“Š {selected_model} ({category}) ë¶„ì„")
        st.markdown("---")

        df_final = load_data(folder_path, selected_model, category)
        safe_name = selected_model.replace(" ", "_")
        cat_lower = category.lower()
        path_specific = os.path.join(MODEL_DIR, f"{cat_lower}_{safe_name}_model.h5")
        path_generic = os.path.join(MODEL_DIR, f"{cat_lower}_model.h5")
        final_model_path = path_specific if os.path.exists(path_specific) else (path_generic if os.path.exists(path_generic) else None)
        scaler_candidates = [
            os.path.join(MODEL_DIR, f"{cat_lower}_{safe_name}_scaler.pkl"),
            os.path.join(MODEL_DIR, f"{cat_lower}_scaler.pkl"),
            os.path.join(MODEL_DIR, f"{cat_lower}_model.pkl")
        ]
        final_scaler_path = next((p for p in scaler_candidates if os.path.exists(p)), None)
        has_model = (final_model_path is not None) and (final_scaler_path is not None)

        if df_final is not None:
            st.header("1. ëª¨ë¸ ì„±ëŠ¥ ë° ì •í™•ë„")
            if has_model:
                try:
                    model_ai = load_model(final_model_path)
                    scaler_ai = joblib.load(final_scaler_path)
                    SEQ_LENGTH = 30
                    scaled_data = scaler_ai.transform(df_final[['Price_Smooth']])
                    if len(scaled_data) > SEQ_LENGTH:
                        X_val = np.array([scaled_data[i:i+SEQ_LENGTH] for i in range(len(scaled_data)-SEQ_LENGTH)])
                        y_pred = scaler_ai.inverse_transform(model_ai.predict(X_val, verbose=0))
                        y_actual = df_final['Price_Smooth'].values[SEQ_LENGTH:]
                        m1, m2, m3, m4 = st.columns(4)
                        m1.metric("RÂ² Score", f"{r2_score(y_actual, y_pred):.4f}")
                        m2.metric("MAE", f"{mean_absolute_error(y_actual, y_pred):,.0f}ì›")
                        m3.metric("MSE", f"{mean_squared_error(y_actual, y_pred):,.0f}")
                        m4.metric("RMSE", f"{np.sqrt(mean_squared_error(y_actual, y_pred)):,.0f}ì›")
                    else: st.warning("ë°ì´í„° ë¶€ì¡±")
                except Exception as e: st.error(f"ì—ëŸ¬: {e}"); has_model = False
            else: st.info("í•™ìŠµëœ ëª¨ë¸ ì—†ìŒ")

            st.markdown("---"); st.header("2. ì£¼ìš” ë³€ìˆ˜ë³„ ë°ì´í„° ë¶„í¬")
            c1, c2, c3 = st.columns(3)
            with c1:
                fig, ax = plt.subplots(); sns.histplot(df_final['Price_Raw'], kde=True, ax=ax, color='skyblue'); st.subheader("ğŸ’° ê°€ê²© ë¶„í¬"); st.pyplot(fig)
            with c2:
                fig, ax = plt.subplots(); sns.countplot(data=df_final, x='DayOfWeek', palette='viridis', ax=ax); st.subheader("ğŸ“… ìš”ì¼ë³„ ë¹ˆë„"); st.pyplot(fig)
            with c3:
                fig, ax = plt.subplots(); sns.countplot(data=df_final, x='Month', palette='magma', ax=ax); st.subheader("ğŸ“… ì›”ë³„ ë¹ˆë„"); st.pyplot(fig)

            st.markdown("---"); st.header("3. ì‹œì„¸ ì¶”ì´ ë° ë¯¸ë˜ ì˜ˆì¸¡")
            tab1, tab2 = st.tabs(["ê³¼ê±° ë°ì´í„°", "ë¯¸ë˜ ì˜ˆì¸¡"])
            with tab1:
                fig, ax = plt.subplots(figsize=(12, 5))
                ax.plot(df_final['Date_dt'], df_final['Price_Raw'], label='Raw', alpha=0.5)
                ax.plot(df_final['Date_dt'], df_final['Price_Smooth'], label='Trend', color='red')
                ax.legend(); st.pyplot(fig)
            with tab2:
                if has_model:
                    last_seq = scaled_data[-SEQ_LENGTH:]
                    future_preds = []
                    for _ in range(90):
                        nxt = model_ai.predict(last_seq.reshape(1, SEQ_LENGTH, 1), verbose=0)
                        future_preds.append(nxt[0])
                        last_seq = np.append(last_seq[1:], nxt, axis=0)
                    future_prices = scaler_ai.inverse_transform(future_preds)
                    last_date = df_final['Date_dt'].max()
                    future_dates = [last_date + timedelta(days=i) for i in range(1, 91)]
                    fig, ax = plt.subplots(figsize=(12, 5))
                    ax.plot(future_dates, future_prices, color='red', label='Future 90 Days')
                    ax.grid(True, linestyle='--', alpha=0.3)
                    ax.legend(); st.pyplot(fig)
                    diff = future_prices[-1][0] - future_prices[0][0]
                    if diff < -5000: st.success(f"ğŸ“‰ í•˜ë½ ì˜ˆìƒ (-{abs(diff):,.0f}ì›)")
                    elif diff > 5000: st.warning(f"ğŸ“ˆ ìƒìŠ¹ ì˜ˆìƒ (+{diff:,.0f}ì›)")
                    else: st.info("âš–ï¸ ë³´í•©ì„¸ ì˜ˆìƒ")
                else: st.write("ëª¨ë¸ ì—†ìŒ")
        else: st.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")

# =============================================================================
# [MODE 2] ë§ˆìš°ìŠ¤ ê°€ìƒ í”¼íŒ…ë£¸ (íŒŒì´í”„ë¼ì¸ ì›ë³µ + ë„“ì´ ì˜¤ì°¨ ì¶”ê°€)
# =============================================================================
elif page_mode == "ğŸ–±ï¸ ë§ˆìš°ìŠ¤ ê°€ìƒ í”¼íŒ…ë£¸":
    st.title("ğŸ–±ï¸ ë§ˆìš°ìŠ¤ ê°€ìƒ í”¼íŒ…ë£¸ (3-Step Calibration)")

    df_mouse = load_mouse_data()
    if 'camera_on' not in st.session_state: st.session_state['camera_on'] = False
    if 'result_data' not in st.session_state: st.session_state['result_data'] = None

    st.sidebar.markdown("---")
    st.sidebar.header("âš™ï¸ ì¹´ë©”ë¼ ì„¤ì •")
    cam_id = st.sidebar.selectbox("ğŸ“· ì¹´ë©”ë¼ ë²ˆí˜¸", [0, 1, 2, 3], index=0)
    
    if st.session_state['camera_on']:
        st.sidebar.success(f"ğŸŸ¢ [ì±„ë„ {cam_id}] ì—°ê²°ë¨")
    else:
        st.sidebar.info("âšª ì¹´ë©”ë¼ ëŒ€ê¸° ì¤‘")

    st.markdown("### ğŸ“ Step 1: ë‚´ ì† ì‹¤ì¸¡ê°’ ì…ë ¥")
    st.info("""
    **ğŸ“ ì •í™•í•œ ì¸¡ì •ì„ ìœ„í•œ ê¸°ì¤€ (í•„ë…):**
    * **ê¸¸ì´(L):** ì†ëª© **ê´€ì ˆ ì¤‘ì•™(ì ‘íˆëŠ” ë¶€ë¶„)** ~ **ì¤‘ì§€ ë**
    * **ë„ˆë¹„(W):** **ê²€ì§€** ë¿Œë¦¬ ê´€ì ˆ ~ **ìƒˆë¼** ë¿Œë¦¬ ê´€ì ˆ (**ì—„ì§€ ì œì™¸**)
    """)
    c1, c2 = st.columns(2)
    with c1: user_hand_l = st.number_input("ğŸ“ ì‹¤ì œ ì† ê¸¸ì´ (mm)", 100, 250, 180)
    with c2: user_hand_w = st.number_input("ğŸ“ ì‹¤ì œ ì† ë„ˆë¹„ (mm)", 50, 150, 85)

    st.markdown("---")
    st.markdown("### ğŸ–±ï¸ Step 2: ë§ˆìš°ìŠ¤ ì„ íƒ")
    if not df_mouse.empty:
        col_sel1, col_sel2 = st.columns([1, 2])
        with col_sel1:
            brand_list = ["All"] + sorted(df_mouse['Brand'].unique().tolist())
            selected_brand = st.selectbox("ì œì¡°ì‚¬ í•„í„°", brand_list)
        with col_sel2:
            if selected_brand != "All": filtered_df = df_mouse[df_mouse['Brand'] == selected_brand]
            else: filtered_df = df_mouse
            selected_mouse_name = st.selectbox("ëª¨ë¸ëª… ê²€ìƒ‰", filtered_df['Name'].unique())
        
        selected_mouse_info = df_mouse[df_mouse['Name'] == selected_mouse_name].iloc[0]
        
        col_info, col_img = st.columns([3, 1])
        with col_info:
            cc1, cc2, cc3 = st.columns(3)
            cc1.metric("ê¸¸ì´", f"{selected_mouse_info['Length']} mm")
            cc2.metric("ë„ˆë¹„", f"{selected_mouse_info['Width']} mm")
            cc3.metric("ê°€ê²©", f"{int(selected_mouse_info['Price']):,} ì›")
        with col_img:
            if pd.notna(selected_mouse_info['image_url']):
                st.image(selected_mouse_info['image_url'], use_column_width=True)
            else: st.text("ì´ë¯¸ì§€ ì—†ìŒ")

    st.markdown("---")
    st.markdown("### ğŸ¥ Step 3: ê°€ìƒ í”¼íŒ… ì‹œì‘")
    st.info("""
    **âœ¨ ì‚¬ìš©ë²•:**
    1. **Monitor 10cm:** ì»¨íŠ¸ë¡¤ ì°½ì˜ ìŠ¬ë¼ì´ë”ë¥¼ ì›€ì§ì—¬ íŒŒë€ ì„ ì„ ì‹¤ì œ ìì˜ 10cmì™€ ë§ì¶”ì„¸ìš”.
    2. **Cam Scale:** ì²­ë¡ìƒ‰ ë°•ìŠ¤ì— ì†ì„ ë§ì¶”ì„¸ìš”.
    3. **ìº¡ì²˜:** ì´ˆë¡ìƒ‰ ë°•ìŠ¤ê°€ ëœ¨ë©´ 5ì´ˆê°„ ìœ ì§€í•˜ì„¸ìš”.
    """)

    btn_text = "ğŸŸ¥ í”¼íŒ… ì¢…ë£Œ" if st.session_state['camera_on'] else "ğŸŸ© ê°€ìƒ í”¼íŒ… ì‹œì‘ (Start AR)"
    if st.button(btn_text, use_container_width=True):
        st.session_state['camera_on'] = not st.session_state['camera_on']
        if st.session_state['camera_on']: st.session_state['result_data'] = None
        st.rerun()

    if st.session_state['camera_on'] and not df_mouse.empty:
        cap = cv2.VideoCapture(cam_id, cv2.CAP_DSHOW)
        time.sleep(0.5) 
        
        if not cap.isOpened():
            st.error(f"ğŸš¨ {cam_id}ë²ˆ ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨.")
            st.sidebar.error("ğŸ”´ ì—°ê²° ì‹¤íŒ¨")
            st.session_state['camera_on'] = False
        else:
            window_name = "AR Fitting Mode"
            ctrl_name = "Calibration Panel"
            cv2.namedWindow(ctrl_name, cv2.WINDOW_NORMAL); cv2.resizeWindow(ctrl_name, 400, 500)
            
            cv2.createTrackbar("Monitor 10cm", ctrl_name, 100, 300, nothing)
            cv2.createTrackbar("Cam Scale", ctrl_name, 35, 100, nothing)
            cv2.createTrackbar("Alpha (%)", ctrl_name, 90, 100, nothing)
            cv2.createTrackbar("Angle (+90)", ctrl_name, 90, 180, nothing)
            cv2.createTrackbar("Pos X (+100)", ctrl_name, 100, 200, nothing)
            cv2.createTrackbar("Pos Y (+100)", ctrl_name, 100, 200, nothing)
            cv2.namedWindow(window_name, cv2.WINDOW_NORMAL); cv2.resizeWindow(window_name, 1280, 720)

            mp_hands = mp.solutions.hands
            mp_drawing = mp.solutions.drawing_utils
            
            fit_start_time = None
            capture_success = False
            final_meas_l = 0; final_meas_w = 0; final_px_per_mm = 0
            img_hand_crop = None; img_mouse_clean = None
            
            hand_angle = 0
            grip_center_rel = (0, 0)

            with mp_hands.Hands(max_num_hands=1, model_complexity=0) as hands:
                current_mouse_img = get_mouse_image_from_url(selected_mouse_info['image_url'])
                ctrl_bg = np.zeros((500, 400, 3), dtype=np.uint8)
                # [ìŠ¤íƒ€ì¼] AA ì ìš© (í°íŠ¸ SIMPLEX)
                cv2.putText(ctrl_bg, "CONTROLS", (20, 40), MY_FONT, 0.7, (255, 255, 255), 2, cv2.LINE_AA)

                while cap.isOpened() and st.session_state['camera_on']:
                    ret, frame = cap.read()
                    if not ret: break
                    frame = cv2.resize(frame, (1280, 720)); frame = cv2.flip(frame, 1)
                    h, w, _ = frame.shape
                    
                    try:
                        val_monitor = max(0.1, cv2.getTrackbarPos("Monitor 10cm", ctrl_name) / 100.0)
                        val_cam = max(5, cv2.getTrackbarPos("Cam Scale", ctrl_name))
                        val_alpha = cv2.getTrackbarPos("Alpha (%)", ctrl_name)/100.0
                        val_angle = cv2.getTrackbarPos("Angle (+90)", ctrl_name)-90
                        val_x = cv2.getTrackbarPos("Pos X (+100)", ctrl_name)-100
                        val_y = cv2.getTrackbarPos("Pos Y (+100)", ctrl_name)-100
                    except: break

                    # í‘œì¤€ ëª¨ë‹ˆí„° í•´ìƒë„ 96DPI ê¸°ì¤€ 10cm í‘œí˜„í• ë•Œ í•„ìš”í•œ í”½ì…€ ìˆ˜
                    monitor_10cm_px = int(378 * val_monitor)
                    
                    # [ìŠ¤íƒ€ì¼] ì„  ë‘ê»˜ 2, AA, Cyan ìƒ‰ìƒ
                    cv2.line(frame, (50, h-50), (50+monitor_10cm_px, h-50), (255, 255, 0), 2, cv2.LINE_AA)
                    cv2.putText(frame, "10cm Ruler", (50, h-70), MY_FONT, 0.6, (255, 255, 0), 1, cv2.LINE_AA)
                    
                    t_h, t_w = int((user_hand_l/10)*val_cam*val_monitor), int((user_hand_w/10)*val_cam*val_monitor)
                    cx, cy = w // 2, h // 2
                    tl, br = (cx-t_w//2, cy-t_h//2), (cx+t_w//2, cy+t_h//2)
                    
                    box_color, msg = (200, 200, 200), "Fit Hand Here"
                    
                    # 1. ì´ë¯¸ì§€ ìƒ‰ê³µê°„ ë³€í™˜ : BRG Image -> RGB(MediaPipe ëª¨ë¸ ìš”êµ¬ì‚¬í•­)
                    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    
                    # 2. ë”¥ëŸ¬ë‹ ëª¨ë¸ ì¶”ë¡ 
                    results = hands.process(img_rgb)
                    
                    if results.multi_hand_landmarks:
                        for hl in results.multi_hand_landmarks:
                            # 21ê°œ ëœë“œë§ˆí¬ì˜ ì •ê·œí™”ëœ ì¢Œí‘œ(0.0 ~ 1.0) í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
                            mp_drawing.draw_landmarks(frame, hl, mp_hands.HAND_CONNECTIONS)
                            
                            # í•µì‹¬ ëœë“œë§ˆí¬ ì¶”ì¶œ (0: ì†ëª©, 12: ì¤‘ì§€ ë, 5: ê²€ì§€ ë¿Œë¦¬, 17: ìƒˆë¼ ë¿Œë¦¬)
                            p0, p12 = hl.landmark[0], hl.landmark[12]
                            p5, p17 = hl.landmark[5], hl.landmark[17]
                            
                            # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³µì‹ì„ í™œìš©í•œ ì†ì˜ ê¸¸ì´ì™€ ë„ˆë¹„(pixel ë‹¨ìœ„) ê³„ì‚°
                            dist_l_px = math.sqrt((p12.x*w-p0.x*w)**2 + (p12.y*h-p0.y*h)**2)
                            dist_w_px = math.sqrt((p17.x*w-p5.x*w)**2 + (p17.y*h-p5.y*h)**2)

                            # Calibration : í”½ì…€ ë‹¨ìœ„ë¥¼ ì‹¤ì œ ë¬¼ë¦¬ì  ê±°ë¦¬ë¡œ ë³€í™˜
                            meas_l = (dist_l_px / (val_cam * val_monitor)) * 10
                            meas_w = (dist_w_px / (val_cam * val_monitor)) * 10
                            
                            # ì‹¤ì œ ì…ë ¥í•œ ìˆ˜ì¹˜ - AI ì¸¡ì •ê°’ ì‚¬ì´ ì˜¤ì°¨ ê³„ì‚°
                            diff_l = meas_l - user_hand_l   # ì† ê¸¸ì´
                            diff_w = meas_w - user_hand_w   # ì† ë„ˆë¹„
                            
                            # ì˜¤ì°¨ ë²”ìœ„(5mm)ì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ìƒ‰ìƒ ê²°ì •(Passì‹œ ì´ˆë¡)
                            col_l = (0, 255, 0) if abs(diff_l) < 5 else (0, 0, 255)
                            col_w = (0, 255, 0) if abs(diff_w) < 5 else (0, 0, 255)

                            # ì‹¤ì‹œê°„ ì¸¡ì • ë° ì˜¤ì°¨ìœ¨ í™”ë©´ ìƒë‹¨ì— ì¶œë ¥
                            cv2.putText(frame, f"Hand L: {meas_l:.1f}mm (Err: {diff_l:+.1f})", (30, 50), MY_FONT, 0.7, col_l, 1, cv2.LINE_AA)
                            cv2.putText(frame, f"Hand W: {meas_w:.1f}mm (Err: {diff_w:+.1f})", (30, 80), MY_FONT, 0.7, col_w, 1, cv2.LINE_AA)
                            
                            # ì¡´ì´ ì¤‘ì•™ ë°•ìŠ¤ì— ìœ„ì¹˜ í–ˆëŠ”ì§€ í™•ì¸
                            h_cx, h_cy = (p0.x*w + p12.x*w) // 2, (p0.y*h + p12.y*h) // 2
                            dist_c = math.sqrt((h_cx - cx)**2 + (h_cy - cy)**2)
                            
                            # Width, Length 5mm ì´ë‚´ and ì¤‘ì•™ ì •ë ¬ ì‹œ 5ì´ˆ ì¹´ìš´íŠ¸ ì‹œì‘
                            if abs(diff_l) < 5 and dist_c < 60: 
                                box_color = (0, 255, 0) # ë°•ìŠ¤ ìƒ‰ìƒ ì´ˆë¡ìœ¼ë¡œ ë³€ê²½
                                if fit_start_time is None: fit_start_time = time.time()
                                elap = time.time() - fit_start_time
                                if 5.0 - elap > 0:
                                    msg = f"Hold: {5.0-elap:.1f}s"  # ë‚¨ì€ ì‹œê°„
                                    bw = int((elap/5.0)*t_w)        # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ë„ˆë¹„ ê³„ì‚°
                                    cv2.rectangle(frame, (tl[0], tl[1]-20), (tl[0]+bw, tl[1]-10), (0, 255, 0), -1)
                                else:
                                    # 5ì´ˆ ëŒ€ê¸° ì™„ë£Œ ë° ë°ì´í„° í™•ì •ì¼ ê²½ìš° ìº¡ì²˜ ì„±ê³µ
                                    msg, capture_success = "Complete!", True
                                    final_meas_l, final_meas_w = meas_l, meas_w
                                    final_px_per_mm = monitor_10cm_px / 100.0
                                    
                                    # ì†ëª©(p0), ì¤‘ì§€ ë„ˆí´(P9)ì‚¬ì´ì˜ ê¸°ìš¸ê¸°ë¥¼ êµ¬í•´ ë§ˆìš°ìŠ¤ ê°ë„ íšŒì „
                                    p9 = hl.landmark[9]
                                    dx = p9.x*w - p0.x*w
                                    dy = p9.y*h - p0.y*h
                                    
                                    # atan2ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¼ë””ì•ˆ -> ê°ë„ ë³€í™˜
                                    hand_angle = -90 - math.degrees(math.atan2(dy, dx))
                                    
                                    # ê²°ê³  ë¦¬í¬íŠ¸ìš© ì† ì´ë¯¸ì§€ ìë¥´ê¸°
                                    x_list = [lm.x * w for lm in hl.landmark]
                                    y_list = [lm.y * h for lm in hl.landmark]
                                    x_min, x_max = max(0, int(min(x_list))-30), min(w, int(max(x_list))+30)
                                    y_min, y_max = max(0, int(min(y_list))-30), min(h, int(max(y_list))+30)
                                    img_hand_crop = frame[y_min:y_max, x_min:x_max].copy()
                                    img_mouse_clean = current_mouse_img
                                    
                                    # ì†ê°€ë½ ë¿Œë¦¬ ê´€ì ˆ(ë„ˆí´, p5, p9)ì˜ ì¤‘ì ì„ ë§ˆìš°ìŠ¤ í•©ì„±ì˜ ê¸°ì¤€ì ìœ¼ë¡œ ì§€ì •
                                    p5_lm = hl.landmark[5]
                                    abs_grip_x = (p5_lm.x*w + p9.x*w) / 2
                                    abs_grip_y = (p5_lm.y*h + p9.y*h) / 2
                                    grip_center_rel = (int(abs_grip_x - x_min), int(abs_grip_y - y_min))
                                    
                            else:
                                # ì¡°ê±´ ë¯¸ë‹¬ì¼ ê²½ìš° ì¹´ìš´íŠ¸ë‹¤ìš´ ì´ˆê¸°í™” ë° ì•ˆë‚´ ë§¤ì„¸ì§€ ë³€ê²½
                                fit_start_time = None
                                if abs(diff_l) >= 5: msg = "Size Mismatch"
                                elif dist_c >= 60: msg = "Center Hand"

                            # ì‹¤ì‹œê°„ ë§ˆìš°ìŠ¤ ì´ë¯¸ì§€ í•©ì„± : ì† + ë§ˆìš°ìŠ¤ í¬ê¸° ì¸¡ì • ì‹œ 
                            if current_mouse_img is not None:
                                # ë§ˆìš°ìŠ¤ ì œì› ê¸¸ì´ ê¸°ë°˜ í”½ì…€ í¬ê¸° ì‹¤ì‹œê°„ìœ¼ë¡œ ì¡°ì •
                                m_h = int(((selected_mouse_info['Length']/10)*val_cam)*val_monitor)
                                r = m_h / current_mouse_img.shape[0]
                                m_w = int(current_mouse_img.shape[1] * r)
                                
                                # ì† ê°ë„ì— ë§ì¶° ë§ˆìš°ìŠ¤ íšŒì „
                                rm = rotate_image(cv2.resize(current_mouse_img, (m_w, m_h)), val_angle)
                                # ì¤‘ì§€ ê´€ì ˆ ìœ„ì¹˜ì— ë§ˆìš°ìŠ¤ ë°°ì¹˜ ë° ì˜¤ë²„ë ˆì´ í•©ì„±
                                mc = hl.landmark[9]
                                dx, dy = int(mc.x*w - rm.shape[1]//2 + val_x), int(mc.y*h - rm.shape[0]//2 + val_y)
                                
                                # ê³„ì‚°ëœ ì¢Œí‘œ dx, dyì— ë°°ê²½ íˆ¬ëª…ë„ë¥¼ ìœ ì§€í•˜ë©° í•©ì„±
                                frame = overlay_transparent(frame, rm, dx, dy, overlay_size=None, global_alpha=val_alpha)
                                display_name = selected_mouse_name if selected_mouse_name.isascii() else "Mouse Model"
                                
                                # [ìŠ¤íƒ€ì¼] AA ì ìš©
                                cv2.putText(frame, f"Mouse: {display_name}", (dx, dy-10), MY_FONT, 0.6, (255, 255, 255), 1, cv2.LINE_AA)
                                cv2.putText(frame, f"{selected_mouse_info['Length']}x{selected_mouse_info['Width']}mm", (30, 120), MY_FONT, 0.7, (255, 255, 255), 1, cv2.LINE_AA)

                    # [ìŠ¤íƒ€ì¼] ë°•ìŠ¤ ë‘ê»˜ 1, AA ì ìš©
                    cv2.rectangle(frame, tl, br, box_color, 1, cv2.LINE_AA)
                    cv2.putText(frame, msg, (cx-100, tl[1]-10), MY_FONT, 0.7, box_color, 1, cv2.LINE_AA)
                    cv2.imshow(window_name, frame); cv2.imshow(ctrl_name, ctrl_bg)
                    
                    # ë£¨í”„ ì¢…ë£Œ ì¡°ê±´ ê²€ì‚¬
                    # -qí‚¤ ì…ë ¥ì‹œ ì¢…ë£Œ
                    # capture_successê°€ Trueì¼ ê²½ìš°(5ì´ˆ ëŒ€ê¸° ì„±ê³µ ì‹œ) ìë™ ì¢…ë£Œ 
                    if cv2.waitKey(1) & 0xFF == ord('q') or capture_success: break
                    try:
                        
                        # ì˜ˆì™¸ì²˜ë¦¬: ì‚¬ìš©ìê°€ ì°½ì„ ë‹«ì„ ê²½ìš° ì˜ˆì™¸ì—†ì´ ë£¨í”„ ë¹ ì ¸ë‚˜ê°€ê¸°
                        if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1: break
                        if cv2.getWindowProperty(ctrl_name, cv2.WND_PROP_VISIBLE) < 1: break
                    except: break
            # ìì›í•´ì œ ë° ìƒíƒœ ì´ˆê¸°í™”, Streamlit ì¹´ë©”ë¼ ì„¸ì…˜ offë¡œ ë³€ê²½
            cap.release(); cv2.destroyAllWindows(); st.session_state['camera_on'] = False
            
            # ë°ì´í„° í›„ì²˜ë¦¬ ë° ìµœì¢… ì €ì¥ 
            if capture_success:
                # OpenCV(BGR) ì´ë¯¸ì§€ Streamlit(RGB) ì¶œë ¥ìš© ë³€í™˜
                if img_hand_crop is not None: img_hand_crop = cv2.cvtColor(img_hand_crop, cv2.COLOR_BGR2RGB)
                if img_mouse_clean is not None: img_mouse_clean = cv2.cvtColor(img_mouse_clean, cv2.COLOR_BGRA2RGBA)

                # ê²°ê³¼ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ í˜•ìœ¼ë¡œ êµ¬ì¡°í™”
                # ê²°ê³¼ ë¦¬í¬íŠ¸ ë°ì´í„° ì¶œë ¥ ìë£Œí˜•
                st.session_state['result_data'] = {
                    'mouse': selected_mouse_name,   # ë§ˆìš°ìŠ¤ ëª¨ë¸ëª…
                    'mouse_len': selected_mouse_info['Length'], # ë§ˆìš°ìŠ¤ ì‹¤ì œ ê¸¸ì´ ìŠ¤í™
                    'user_l': user_hand_l,  # ì‚¬ìš©ì ì…ë ¥ ì† ê¸¸ì´
                    'user_w': user_hand_w,  # ì‚¬ìš©ì ì…ë ¥ ì† ë„ˆë¹„
                    'meas_l': final_meas_l, # AI ì¸¡ì • ì† ê¸¸ì´
                    'meas_w': final_meas_w, # AI ì¸¡ì • ì† ë„ˆë¹„
                    'diff_l': final_meas_l - user_hand_l,   # ê¸¸ì´ ì¸¡ì • ì˜¤ì°¨
                    'diff_w': final_meas_w - user_hand_w,   # ë„ˆë¹„ ì¸¡ì • ì˜¤ì°¨
                    'img_hand': img_hand_crop, # ìº¡ì²˜ëœ ì‹¤ì œ ì† ì´ë¯¸ì§€
                    'img_mouse': img_mouse_clean,   # ê°€ìƒ í”¼íŒ…ì— ì‚¬ìš©ëœ ë§ˆìš°ìŠ¤ ì´ë¯¸ì§€
                    'px_per_mm': final_px_per_mm,   # 1:1 ë°°ìœ¨ ì¬í˜„ì„ ìœ„í•œ í”½ì…€ ë°°ìœ¨
                    'hand_angle': hand_angle,       # ì†ì˜ íšŒì „ ê°ë„ ë°ì´í„°
                    'grip_center': grip_center_rel  # ë§ˆìš°ìŠ¤ í•©ì„± ê¸°ì¤€ì  ì¢Œí‘œ
                }
                st.balloons();  # ì¶•í•˜ ì• ë‹ˆë©”ì´ì…˜
                st.rerun()      # í™”ë©´ ìƒˆë¡œê³ ì¹¨ í›„ ê²°ê³¼ ë¦¬í¬íŠ¸ ë ˆì´ì•„ì›ƒ ì¶œë ¥

    if st.session_state.get('result_data'):
        st.markdown("""
        <style>
        div[data-testid="stImage"] {
            justify-content: center;
            display: flex;
            align-items: center;
            width: 100%;
        }
        div[data-testid="stImage"] > img {
            margin-left: auto;
            margin-right: auto;
            display: block;
        }
        </style>
        """, unsafe_allow_html=True)

        res = st.session_state['result_data']
        st.divider()
        st.success("ğŸ‰ ì¸¡ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! (1:1 Real Scale View)")
        
        c1, c2, c3 = st.columns(3)
        c1.metric("ğŸ–ï¸ ë‚´ ì† ì¸¡ì •ê°’", f"{res['meas_l']:.1f} x {res['meas_w']:.1f} mm")
        diff_l, diff_w = res['diff_l'], res['diff_w']
        c2.metric("ğŸ“ ê¸¸ì´ ì˜¤ì°¨", f"{diff_l:+.1f} mm", delta_color="inverse" if abs(diff_l) > 5 else "normal")
        c3.metric("ğŸ“ ë„ˆë¹„ ì˜¤ì°¨", f"{diff_w:+.1f} mm", delta_color="inverse" if abs(diff_w) > 5 else "normal")

        st.markdown("### ğŸ“· ì‹¤ì œ í¬ê¸° ë¹„êµ & ê°€ìƒ ê·¸ë¦½ (1:1 Scale)")
        st.info("ğŸ’¡ **ê²€ì¦ ë°©ë²•:** í™”ë©´ ì† íŒŒë€ìƒ‰ ë°”(Bar)ì— ì‹¤ì œ ìë¥¼ ëŒ€ë³´ì„¸ìš”. ë°”ì˜ ê¸¸ì´ê°€ ì •í™•íˆ **5cm**ì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        ratio = res['px_per_mm']
        bar_len_px = int(50 * ratio) 
        bar_img = np.zeros((20, bar_len_px, 3), dtype=np.uint8); bar_img[:] = (0, 0, 255)
        
        # [í•µì‹¬] ë„ˆí´ ê¸°ì¤€ í•©ì„± (ìœ ì§€)
        composite_img = res['img_hand'].copy()
        if res['img_mouse'] is not None:
            h_m, w_m = res['img_mouse'].shape[:2]
            target_h = int(res['mouse_len'] * ratio)
            target_w = int(target_h * (w_m / h_m))
            resized_mouse = cv2.resize(res['img_mouse'], (target_w, target_h))
            
            rotated_mouse, M_rot = rotate_image_with_matrix(resized_mouse, res['hand_angle'])
            
            mouse_cx = rotated_mouse.shape[1] // 2
            mouse_cy = rotated_mouse.shape[0] // 2
            dx = res['grip_center'][0] - mouse_cx
            dy = res['grip_center'][1] - mouse_cy

            if rotated_mouse.shape[2] == 4:
                 rotated_mouse = cv2.cvtColor(rotated_mouse, cv2.COLOR_BGRA2RGBA)
            composite_img = overlay_transparent(composite_img, rotated_mouse, int(dx), int(dy), overlay_size=None, global_alpha=0.85)

        st.markdown("---")
        
        c_r1_c1, c_r1_c2 = st.columns(2)
        with c_r1_c1:
            st.markdown("<h5 style='text-align: center;'>1. ë‚´ ì† (Captured Hand)</h5>", unsafe_allow_html=True)
            st.image(res['img_hand'], width=res['img_hand'].shape[1])
            st.markdown("<p style='text-align: center;'>â–¼ 5cm ê²€ì¦ ë°”</p>", unsafe_allow_html=True)
            st.image(bar_img, width=bar_len_px)
            
        with c_r1_c2:
            st.markdown("<h5 style='text-align: center;'>2. ë§ˆìš°ìŠ¤ ì‹¤ì œ í¬ê¸° (Mouse Size)</h5>", unsafe_allow_html=True)
            if res['img_mouse'] is not None:
                h, w, _ = res['img_mouse'].shape
                target_h_px = int(res['mouse_len'] * ratio)
                target_w_px = int(target_h_px * (w / h))
                if target_w_px > 0:
                    resized_m = cv2.resize(res['img_mouse'], (target_w_px, target_h_px))
                    st.image(resized_m, width=target_w_px)
                st.markdown("<p style='text-align: center;'>â–¼ 5cm ê²€ì¦ ë°”</p>", unsafe_allow_html=True)
                st.image(bar_img, width=bar_len_px)
        
        st.markdown("---")

        c_r2_c1, c_r2_c2 = st.columns(2)
        with c_r2_c1:
             st.markdown("<h5 style='text-align: center;'>â˜… 3. ê°€ìƒ ê·¸ë¦½ (Virtual Grip Overlay)</h5>", unsafe_allow_html=True)
             st.image(composite_img, width=composite_img.shape[1])
             st.markdown("<p style='text-align: center;'>â–¼ 5cm ê²€ì¦ ë°”</p>", unsafe_allow_html=True)
             st.image(bar_img, width=bar_len_px)
        with c_r2_c2:
             pass

        if st.button("ğŸ”„ ë‹¤ì‹œ ì¸¡ì •í•˜ê¸°", use_container_width=True): st.session_state['result_data'] = None; st.rerun()